{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "plt.set_cmap(\"RdBu_r\")\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from sklearn.model_selection import KFold, ParameterGrid, BaseCrossValidator, train_test_split\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(X_A, X_B=None):\n",
    "    \"\"\"\n",
    "    Calculate linear kernel matrix between two sets of feature-vectors, so that:\n",
    "\n",
    "        k_ij = <x_i, x_j>\n",
    "\n",
    "    :param X_A: array-like, shape=(n_samples_A, d), feature-matrix of set A\n",
    "    :param X_B: array-like, shape=(n_samples_B, d), feature-matrix of set B or None, than Y = X\n",
    "\n",
    "    :return: array-like, shape=(n_samples_A, n_samples_B), kernel matrix\n",
    "    \"\"\"\n",
    "    if X_B is None:\n",
    "        X_B = X_A\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    K_AB = np.dot(X_A, X_B.T)\n",
    "    \n",
    "    return K_AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_A = np.array([[1], [2], [3], [4]])\n",
    "X_B = np.array([[0], [2], [1]])\n",
    "\n",
    "# Test size\n",
    "np.testing.assert_equal(linear_kernel(X_A, X_B).shape, (4, 3))\n",
    "np.testing.assert_equal(linear_kernel(X_A).shape, (4, 4))\n",
    "\n",
    "# Test values\n",
    "np.testing.assert_equal(linear_kernel(X_A)[0, 0], 1)\n",
    "np.testing.assert_equal(linear_kernel(X_A)[1, 1], 4)\n",
    "np.testing.assert_equal(linear_kernel(X_A)[0, 2], 3)\n",
    "np.testing.assert_equal(linear_kernel(X_A)[2, 0], 3)\n",
    "\n",
    "np.testing.assert_equal(linear_kernel(X_A, X_B)[0, 0], 0)\n",
    "np.testing.assert_equal(linear_kernel(X_A, X_B)[0, 1], 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(X_A, X_B=None, sigma=None):\n",
    "    \"\"\"\n",
    "    Calculate the Gaussian kernel matrix, so that\n",
    "\n",
    "        k_ij = exp(-||x_i - x_j||^2 / 2 * sigma^2)\n",
    "\n",
    "    :param X_A: array-like, shape=(n_samples_A, n_features), feature-matrix of set A\n",
    "    :param X_B: array-like, shape=(n_samples_B, n_features), feature-matrix of set B or None, than X_B = X_A\n",
    "    :param sigma: scalar, bandwidth parameter\n",
    "\n",
    "    :return: array-like, shape=(n_samples_A, n_samples_B), kernel matrix\n",
    "    \"\"\"\n",
    "    if X_B is None:\n",
    "        X_B = X_A\n",
    "\n",
    "    n_A = X_A.shape[0]\n",
    "    n_B = X_B.shape[0]\n",
    "\n",
    "    if sigma is None:\n",
    "        sigma = np.sqrt(X_A.shape[1] / 2.0)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    K_AB = np.empty([n_A, n_B])\n",
    "    for i in range(n_A):\n",
    "        for j in range(n_B):\n",
    "            K_AB[i, j] = np.exp(-np.sum((X_A[i, :] - X_B[j, :])**2) / 2*sigma**2)\n",
    "\n",
    "    return K_AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_A = np.array([[1], [2], [3], [4]])\n",
    "X_B = np.array([[0], [2], [1]])\n",
    "\n",
    "# Test size\n",
    "np.testing.assert_equal(gaussian_kernel(X_A, X_B).shape, (4, 3))\n",
    "np.testing.assert_equal(gaussian_kernel(X_A).shape, (4, 4))\n",
    "\n",
    "# Test values\n",
    "np.testing.assert_equal(gaussian_kernel(X_A, sigma=1)[0, 0], 1)\n",
    "np.testing.assert_equal(gaussian_kernel(X_A, sigma=1)[1, 1], 1)\n",
    "np.testing.assert_equal(gaussian_kernel(X_A, sigma=1)[0, 2], np.exp(-2))\n",
    "np.testing.assert_equal(gaussian_kernel(X_A, sigma=1)[2, 0], np.exp(-2))\n",
    "\n",
    "np.testing.assert_equal(gaussian_kernel(X_A, X_B, sigma=1)[0, 0], np.exp(-0.5))\n",
    "np.testing.assert_equal(gaussian_kernel(X_A, X_B, sigma=1)[0, 1], np.exp(-0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParzenWindowClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, kernel=\"gaussian\", sigma=None):\n",
    "        \"\"\"\n",
    "        Parzen Window Classifier\n",
    "\n",
    "        :param kernel: string, specifying which kernel to use. Can be 'gaussian' or 'linear'.\n",
    "        :param sigma: scalar, gaussian kernel parameter, can be None if the linear kernel is used.\n",
    "        \"\"\"\n",
    "        # Parzen Window Classifier model parameter\n",
    "        self.b = None  # bias term\n",
    "        self.alphas = None  # dual variables\n",
    "        \n",
    "        # Training data needed for the prediction phase\n",
    "        self.X_train = None\n",
    "\n",
    "        # Set up kernel function\n",
    "        self.kernel = kernel\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit a Parzen Window Classifier using training data\n",
    "\n",
    "        :param X_train: array-like, shape=(n_samples, n_features), feature-matrix\n",
    "        :param y_train: array-like, shape=(n_samples,) or (n_samples, 1), label vector\n",
    "        \"\"\"\n",
    "        # Calculate the specified kernel\n",
    "        self.X_train = X_train\n",
    "        KX_train = self._get_kernel(self.X_train)\n",
    "\n",
    "        # Get indices of positive and negative examples: I_n, I_p\n",
    "        # YOUR CODE HERE\n",
    "        I_n = np.where(y_train==-1)[0]\n",
    "        I_p = np.where(y_train==1)[0]\n",
    "\n",
    "        # Count the number of postitive and negative examples: n_n, n_p\n",
    "        # YOUR CODE HERE\n",
    "        n_n = len(I_n)\n",
    "        n_p = len(I_p)\n",
    "        \n",
    "        # Calcualte the bias term: self.b\n",
    "        # YOUR CODE HERE\n",
    "        subset_n = X_train[I_n]\n",
    "        subset_p = X_train[I_p]\n",
    "        self.b = -0.5*np.sum(self._get_kernel(subset_n, self.X_train)) / (n_n**2) - 0.5*np.sum(self._get_kernel(subset_p, self.X_train)) / (n_p**2)\n",
    "        # Calculate alpha_i's: self.alpha\n",
    "        self.alphas = np.zeros((n_n + n_p, 1))\n",
    "        # YOUR CODE HERE\n",
    "        self.alphas[np.where(y_train==1)[0]] = 1/n_p\n",
    "        self.alphas[np.where(y_train==-1)[0]] = 1/n_n\n",
    "        \n",
    "    def decision_function(self, X):\n",
    "        \"\"\"\n",
    "        Calculate decision function:\n",
    "            g(x) = sum_i a_i k(x_i, x) + b\n",
    "\n",
    "        :param X: array-like, shape=(n_samples_test, n_features), feature-matrix of new data.\n",
    "        :return: array-like, shape=(n_samples_test,), decision function value g(x) for all new data points\n",
    "        \"\"\"\n",
    "        if self.alphas is None or self.b is None or self.X_train is None:\n",
    "            raise RuntimeError(\"Call fit-function first.\")\n",
    "\n",
    "        # Calculate the specified kernel between the training and test examples\n",
    "        KX_test_train = self._get_kernel(X, self.X_train)\n",
    "        KX_test = self._get_kernel(X, X)\n",
    "\n",
    "        # Calculate the value of the decision function for each test example\n",
    "        # YOUR CODE HERE\n",
    "        g_X = np.sum(np.dot(KX_test_train, self.alphas), axis = 1) + self.b\n",
    "        return g_X.flatten()  # output a one-dimensional vector       \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict labels using Parzen Window Classifier:\n",
    "            h(x) = sign(g(x)), with g(x) being the decision function\n",
    "\n",
    "        :param X: array-like, shape=(n_samples_test, n_features), feature-matrix of new data.\n",
    "        :return: array-like, shape=(n_samples_test,), predicted labels {-1, 1} for all new data points\n",
    "        \"\"\"\n",
    "        if self.alphas is None or self.b is None or self.X_train is None:\n",
    "            raise RuntimeError(\"Call fit-function first.\")\n",
    "        \n",
    "        # Calculate prediction h(x) = sign(g(x))\n",
    "        # YOUR CODE HERE\n",
    "        g_X = self.decision_function(X)\n",
    "        h_X = np.zeros(g_X.shape)\n",
    "        h_X[np.where(g_X>0)[0]] = 1\n",
    "        h_X[np.where(g_X<=0)[0]] = -1\n",
    "        \n",
    "        return h_X\n",
    "\n",
    "    def _get_kernel(self, X, Y=None):\n",
    "        \"\"\"\n",
    "        Calcualte kernel matrix using specified kernel-function and parameters.\n",
    "\n",
    "        :param X: array-like, shape=(n_samples_A, n_features), feature-matrix of set A\n",
    "        :param Y: array-like, shape=(n_samples_B, n_features), feature-matrix of set B or None, than Y = X\n",
    "        :return: array-like, shape=(n_samples_A, n_samples_B), kernel matrix\n",
    "        \"\"\"\n",
    "        if self.kernel == \"gaussian\":\n",
    "            return gaussian_kernel(X, Y, self.sigma)\n",
    "        elif self.kernel == \"linear\":\n",
    "            return linear_kernel(X, Y)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid kernel chosen.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=50, centers=[[1, 1], [1.5, 1.5]], cluster_std=[0.1, 0.1], \n",
    "                  random_state=80)\n",
    "y[y==0] = -1\n",
    "\n",
    "test_est = ParzenWindowClassifier(kernel=\"linear\")\n",
    "test_est.fit(X, y)\n",
    "\n",
    "# Test correct shape of self.b and self.alphas\n",
    "assert(np.isscalar(test_est.b))\n",
    "np.testing.assert_equal(test_est.alphas.shape, (50, 1))\n",
    "\n",
    "# Test correct shape of the predictions\n",
    "X_test = np.array([[1, 1], [1.5, 1.5], [1, 0], [2, 3]])\n",
    "\n",
    "# Validate predictions\n",
    "np.testing.assert_equal(test_est.decision_function(X_test).shape, (4,))\n",
    "\n",
    "np.testing.assert_equal(test_est.predict(X_test).shape, (4,))\n",
    "np.testing.assert_equal(test_est.predict(X_test), np.array([-1, 1, -1, 1]))\n",
    "\n",
    "# Validate score\n",
    "np.testing.assert_equal(test_est.score(X, y), 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic data (Please do not change the random_state!)\n",
    "X_blobs, y_blobs = make_blobs(n_samples=500, centers=[[1, 1], [3, 3]], cluster_std=[0.5, 1.15], \n",
    "                              random_state=80)\n",
    "X_moons, y_moons = make_moons(n_samples=500, noise=0.25, random_state=797)\n",
    "\n",
    "# Make labels being {-1, 1}\n",
    "y_blobs[y_blobs==0] = -1\n",
    "y_moons[y_moons==0] = -1\n",
    "\n",
    "# Split data\n",
    "X_blobs_train, X_blobs_test, y_blobs_train, y_blobs_test = train_test_split(\n",
    "    X_blobs, y_blobs, random_state=319)\n",
    "X_moons_train, X_moons_test, y_moons_train, y_moons_test = train_test_split(\n",
    "    X_moons, y_moons, random_state=747)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot datasets\n",
    "fig, axrr = plt.subplots(1, 2, figsize=(20, 7))\n",
    "\n",
    "# Blobs\n",
    "for l_str, l_num, col in [(\"negative\", -1, \"blue\"), (\"postive\", 1, \"red\")]:    \n",
    "    axrr[0].scatter(\n",
    "        X_blobs_train[y_blobs_train==l_num, 0], X_blobs_train[y_blobs_train==l_num, 1],\n",
    "        c=col, alpha=0.65, label=\"Train (%s)\" % l_str, marker=\"s\")\n",
    "    \n",
    "    axrr[0].scatter(\n",
    "        X_blobs_test[y_blobs_test==l_num, 0], X_blobs_test[y_blobs_test==l_num, 1],\n",
    "        c=col, alpha=0.65, label=\"Test (%s)\" % l_str, marker=\"x\")\n",
    "        \n",
    "# Blobs\n",
    "for l_str, l_num, col in [(\"negative\", -1, \"blue\"), (\"postive\", 1, \"red\")]:    \n",
    "    axrr[1].scatter(\n",
    "        X_moons_train[y_moons_train==l_num, 0], X_moons_train[y_moons_train==l_num, 1],\n",
    "        c=col, alpha=0.65, label=\"Train (%s)\" % l_str, marker=\"s\")\n",
    "    \n",
    "    axrr[1].scatter(\n",
    "        X_moons_test[y_moons_test==l_num, 0], X_moons_test[y_moons_test==l_num, 1],\n",
    "        c=col, alpha=0.65, label=\"Test (%s)\" % l_str, marker=\"x\")\n",
    "\n",
    "\n",
    "axrr[0].set_title(\"Random blobs\", fontsize=\"xx-large\")\n",
    "axrr[0].legend(title=\"Data points\", fontsize=\"x-large\", scatterpoints=3, edgecolor=\"k\")\n",
    "\n",
    "axrr[1].set_title(\"Moons\", fontsize=\"xx-large\")\n",
    "axrr[1].legend(title=\"Data points\", fontsize=\"x-large\", scatterpoints=3, edgecolor=\"k\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
